{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e05c0bb-9330-4aef-ab6e-cfb62bff309e",
   "metadata": {},
   "source": [
    "# Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de84152f-21d4-401c-9d34-dd0102e5a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cfbaa-1328-4ebb-a054-7df399c8d047",
   "metadata": {},
   "source": [
    "# Storing and Extracting Face Encodings for Face Recognition in Video\n",
    "\n",
    "To implement real-time face recognition, it is essential to first assign images of each individual to create unique face encodings. These encodings are extracted using the face_recognition library, which captures distinctive features from the individual's face. Once stored, these encodings are compared against faces detected in real-time video streams to identify and verify individuals accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc2c7907-8c59-4ed4-ae18-9ee9511f761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "harry_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-07 at 8.41.13 PM.png\")\n",
    "harry_encodings = face_recognition.face_encodings(harry_image)[0]\n",
    "\n",
    "hermione_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-07 at 8.39.20 PM.png\")\n",
    "hermione_encodings = face_recognition.face_encodings(hermione_image)[0]\n",
    "\n",
    "ron_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-07 at 8.41.21 PM.png\")\n",
    "ron_encodings = face_recognition.face_encodings(ron_image)[0]\n",
    "\n",
    "macgonagall = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/macgonagall.webp\")\n",
    "mac_encodings = face_recognition.face_encodings(macgonagall)[0]\n",
    "\n",
    "draco = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/draco.webp\")\n",
    "draco_encoding = face_recognition.face_encodings(draco)[0]\n",
    "\n",
    "neville = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/navill.jpg\")\n",
    "neville_encodings = face_recognition.face_encodings(neville)[0]\n",
    "\n",
    "dean = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/dean-thomas_1_1800x1248.jpeg\")\n",
    "dean_encodings = face_recognition.face_encodings(dean)[0]\n",
    "\n",
    "dumbledore = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/dumboldore.webp\")\n",
    "dumbledore_encodings = face_recognition.face_encodings(dumbledore)[0]\n",
    "\n",
    "snape = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/images.jpeg\")\n",
    "snape_encodings = face_recognition.face_encodings(snape)[0]\n",
    "\n",
    "hagrid = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/94e78bcecce6ed3b1de1f3c58c1e55a5.jpg\")\n",
    "hagrid_encodings = face_recognition.face_encodings(hagrid)[0]\n",
    "\n",
    "fred = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/fred .png\")\n",
    "fred_encodings = face_recognition.face_encodings(fred)[0]\n",
    "\n",
    "george = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/george.png\")\n",
    "george_encodings = face_recognition.face_encodings(george)[0]\n",
    "\n",
    "persley = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-09 at 2.18.27 PM.png\")\n",
    "persley_encodings =  face_recognition.face_encodings(persley)[0]\n",
    "\n",
    "ronalda = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/ronalda hooch.webp\")\n",
    "ronalda_encodings = face_recognition.face_encodings(ronalda)[0]\n",
    "\n",
    "known_face_encodings = [harry_encodings, hermione_encodings, ron_encodings, mac_encodings,draco_encoding,neville_encodings\n",
    "                        ,dean_encodings,dumbledore_encodings,snape_encodings, hagrid_encodings,fred_encodings, george_encodings,\n",
    "                       persley_encodings, ronalda_encodings]\n",
    "known_face_names = [\"Harry\",\"Hermione\", \"Ron\",\"Macgonagall\",\"Draco\",\"Neville\",\"Dean Thomas\", \"Dumbledore\",\"Snape\",\"Hagrid\",\n",
    "                   \"Fred\", \"George\", \"Persley\", \"Ronalda Hooch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe47b7-7b97-47ff-8b24-a0c7ac0271ff",
   "metadata": {},
   "source": [
    "# Real-Time Face Recognition with Video Stream Processing\n",
    "\n",
    "This code captures video from a specified file and applies real-time face recognition. It uses the face_recognition library to detect faces in each frame, extracts face encodings, and compares them with known face encodings for identification. The frame count and FPS are displayed, and recognized faces are highlighted with rectangles and labels. Frame processing alternates for efficiency, reducing the load on the system while maintaining real-time performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ca9e288-779b-48e5-88c8-ac3430d9301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture from a file\n",
    "cap = cv2.VideoCapture(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/video.mp4\")\n",
    "process_this_frame = True\n",
    "frame_count = 0\n",
    "fps = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# Check if video file opens correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Video is not opening.\")\n",
    "    \n",
    "# Loop through the video frames\n",
    "while True:\n",
    "    r, frame = cap.read()\n",
    "    if not r:\n",
    "        print(\"Frame is not captured.\")\n",
    "        break\n",
    "\n",
    "    # Increment the frame count and calculate FPS\n",
    "    frame_count += 1\n",
    "    elapsed_time = time.time() - start_time\n",
    "    fps = frame_count / elapsed_time\n",
    "    \n",
    "    # Display frame count and FPS on the video frame\n",
    "    cv2.putText(frame, org=(100, 100), text=f\"Frame count:{frame_count}\", fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                fontScale=1.5, color=(102, 255, 255), thickness=2)\n",
    "    cv2.putText(frame, org=(100, 200), text=f\"FPS: {fps:.2f}\", fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                fontScale=1.5, color=(255, 255, 102), thickness=2)\n",
    "\n",
    "    # Process frames for face detection and recognition\n",
    "    if process_this_frame:\n",
    "        # Resize and convert the frame for faster processing\n",
    "        processing_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        processing_frame = cv2.cvtColor(processing_frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect face locations and encodings in the current frame\n",
    "        face_locations = face_recognition.face_locations(processing_frame)\n",
    "        face_encodings = face_recognition.face_encodings(processing_frame, face_locations)\n",
    "\n",
    "        # Identify the faces based on the encodings\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            name = \"unknown\"\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            distance = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_index = np.argmin(distance)\n",
    "            if matches[best_index]:\n",
    "                name = known_face_names[best_index]\n",
    "            face_names.append(name)\n",
    "\n",
    "    # Draw bounding boxes and names on the detected faces\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale bounding box back to original size\n",
    "        top *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "        right *= 4\n",
    "        \n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), color=(0, 0, 255), thickness=2)\n",
    "        cv2.rectangle(frame, (left, bottom), (right, bottom + 40), color=(0, 0, 255), thickness=cv2.FILLED)\n",
    "        \n",
    "        # Add the name of the person below the face\n",
    "        cv2.putText(frame, org=(left + 6, bottom + 35), text=name, fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    fontScale=1.5, color=(255, 255, 255), thickness=2)\n",
    "        \n",
    "    # Display the frame with the face recognition result\n",
    "    cv2.imshow(\"Video with Face Recognition\", frame)\n",
    "\n",
    "    # Toggle frame processing every alternate frame to improve speed\n",
    "    process_this_frame = not process_this_frame\n",
    "    \n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(12) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b7d68-630a-41db-ae31-5a16c6ec2962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
